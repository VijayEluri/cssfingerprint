<h4><%= link_to "Preliminary results", results_url %> / <%= link_to "Participation page", root_url %></h4>

<h5>Fellow hackers: try to answer <A href="http://stackoverflow.com/questions/2394890/css-js-hacking-detect-visited-styling-on-a-link-without-checking-it-directly">this</A> or <a href="http://stackoverflow.com/questions/2394759/css-cross-browser-reflowing-top-to-bottom-multi-column-lists">this</a>.</h5>

<div id="intro" >
	<h3>About CSS Fingerprint (for geeks)</h3>
	
	<p>What I store is the cookie value you submit, your user-agent, and, for each of the top <s>~2-40k</s> ~100-300k Alexa & Technorati sites (depending on your CPU and internet speed), whether or not you have visited that site.</p>
	
	<p>I make no attempt to find out who you are personally, and I don't store your IP (except temporarily in log files).</p>
	
	<p>The point of this is simply to tell whether I can automatically identify when you visit again with a different browser. To do that, I need training/test data to feed my AI to tell it authoritatively whether two scrapings are the same user or not.</p>
	
	<p>Currently, I'm testing naive Bayes, SVD, and SVM; if you have suggestions for other methods or tweaks to what I'm doing now, please check out the repo and email me.</p>
 	
	<p>A weakness of Panopticlick's method is that it is very browser-specific. That means that while they can fairly well identify your exactly configured browser if you visit again, they cannot easily identify <i>you the human</i> if you visit from multiple computers or browsers, even if your behavior is similar.</p>
	
	<p>The current best 5-fold cross-validation, using a linear SVM kernel, is ~47% (poly ~41%; RBF 46.6%; sigmoid 47.7%). Not too bad, but could definitely be better. (If you think you know how, email me.)</p>
	
	<p>The source code is available at <A href="http://github.com/saizai/cssfingerprint">github</A>. Commits welcome.</p>
</div>

<div id="method">
	<h3>How it works</h3>
	<ol>
		<li>Scrape <a href="http://www.alexa.com/topsites">Alexa</a>'s <a href="http://s3.amazonaws.com/alexa-static/top-1m.csv.zip">1M top sites list</a> and Technorati's <a href="http://technorati.com/blogs/top100">top 100 blogs list</a> once per day, insert in db</li>
		<li>When form is submitted, find/create a user for the cookie, execute the result in <%= THREADS %> parallel iframes</li>
		<li>Form result is code to test a given batch of URLs (500 at a time) and fetch the next one</li>
		<li>The test is based on Jeremiah Grossman's CSS history hack with Daniel Bartlett's modification for IE compatibility. It inserts a link into the DOM, and checks whether it's styled like the stylesheet says visited links should be. It checks http/https and bare/www. URLs.</li>
		<li>Client uploads the results to the server, recursion happens.</li>
		<li>Server cuts off client after 60 seconds, processes all the data in the background to speed things up</li>
	</ol>
</div>

<div id="bugs">	
	<h3>Known issues</h3>
	<ol>
		<li>Alexa top sites list has some glaringly missing things (e.g. mail.google.com, reader.google.com), and the hit rate is consequently rather low (~1% or less). I probably need to supplement it with some other list(s). Suggestions appreciated.</li>
		<li>Lynx, and other browsers that do not fully support CSS/Javascript, will <i>not</i> work correctly. This is not fixable.</li>
		<li>In some circumstances even known visited sites on known supported browsers (e.g. OSX Firefox) don't appear as hits. This may be because my JS scraper has a bug, or because of some browser behavior (e.g. use of a history-blocking plugin).</li>
	</ol>
</div>

<style>
	#graphs div p { text-align: center; }
	#graphs div { float: left; margin-right: 40px; }
</style>
<div id="graphs">	
	<h3>Pretty graphs <small>(all based on live data)</small></h3>
	
	<p>All graphs use only non-bogus combinations with >10 samples, and exclude mobile browsers, as they're 10x slower and distort the graph.</p>
	
	<p>Hue = method; luminosity = browser. Colors are consistent throughout.
		Method names are documented in the <A href="http://github.com/saizai/cssfingerprint/blob/master/public/javascripts/history_scrape.js">Javascript source</A>.</p>
	
	<p>I've deleted all timing data from before I started checking batches in increments of 50, which is why some uncommon browsers' data is missing. Please keep hitting the main page 
		with all your browsers and it'll be nice and smooth.</p>
	
	<div>
		<p>Effect of batch size on local scraping efficency<br/>
		<small>higher z-score = slower to process<br/>all batches are x4 variants</small>
		</p>
		<p><%= image_tag BrowserTest.graph_batch_size %></p>
	</div>
	
	<div>
		<p>Local sraping efficency of different browsers/methods<br/>
		<small>labeled on the best-performing method per browser<br/>
			all numbers are actually x4 if you don't check http/https x plain/www. variants</small>
		</p>
		<p><%= image_tag BrowserTest.graph_method_timings %></p>
	</div>
</div>

<div style="clear:both;"></div>

<div id="stats">
	<h3>Most popular sites</h3>
	
	<p>Sites visited by >10% of users, in order of frequency found</p>
	
	<ul class="multi">
		<% @popular_sites.each do |site| %>
			<li>
				<%= number_to_percentage site.avg_visited * 100, :precision => 0 %>
				<%= link_to site.url, 'http://' + site.url, :style => "text-decoration:none;" %>
			</li>
		<% end %>
	</ul>
</div>
<div style="clear: both;"></div>


<div id="links">
	<h3>Some relevant links</h3>
	
	<ul>
		<li>Jeremiah Grossman's <a href="http://jeremiahgrossman.blogspot.com/2006/08/i-know-where-youve-been.html">original post</a>, <a href="http://ha.ckers.org/weird/CSS-history-hack.cgi">demo page</a>, and <a href="http://ha.ckers.org/weird/CSS-history.cgi">no-JS method</a></li>
		<li>Petko D. (pdp) Petkov's <a href="http://www.gnucitizen.org/blog/attackapi/">AttackAPI</a></li>
		<li>Peter Eckersley &amp; Seth Schoen of EFF's <a href="http://panopticlick.eff.org/">Panopticlick</a>, and articles on <a href="https://www.eff.org/deeplinks/2009/09/new-cookie-technologies-harder-see-and-remove-wide">supercookies</a>, <a href="https://www.eff.org/deeplinks/2010/01/primer-information-theory-and-privacy">information theory</a>, and <a href="http://www.eff.org/deeplinks/2009/09/online-trackers-and-social-networks">social network tracking</a></li>
		<li>Gilbert Wondracek &amp; Thorsten Holz of ISecLab's social network de-anonymization <a href="http://www.iseclab.org/people/gilbert/experiment/">experiment</a> and <a href="http://www.iseclab.org/papers/sonda-TR.pdf">paper</a></li>
		<li>Stuart Robinson's <a href="http://flippingtypical.com/">CSS font detection</a></li>
		<li>Henrik Gemal's all-encompassing <a href="http://browserspy.dk/">BrowserSpy</a></li>
		<li>Collin Jackson, Andrew Bortz, Dan Boneh, &amp; John Mitchell of Stanford Security Lab's Same-Origin Policy <a href="http://crypto.stanford.edu/sameorigin/">Firefox plugin</a> and <a href="http://crypto.stanford.edu/sameorigin/sameorigin.pdf">paper</a></li>
		<li>Markus Jakobsson, Tom N. Jagatic, &amp; Sid Stamm's <a href="https://www.indiana.edu/~phishing/browser-recon/">Browser Recon</a> and <a href="http://www.cs.indiana.edu/~sstamm/papers/invasivesniff05.pdf">paper</a></li>
		<li>Edward Felten &amp; Michael Schneider's paper on <a href="http://www.cs.princeton.edu/sip/pub/webtiming.pdf">timing attacks</a></li>
		<li>Anonymous' <a href="http://www.whattheinternetknowsaboutyou.com/">What the Internet Knows About You</a></li>
	</ul>
</div>

<div id="thanks">
	<h3>Thanks to:</h3>
	<ul>
		<li>Daniel Bartlett - making an (almost) IE-compatible history hack</li>
		<li>Michael Chui - pinpointing the damn MSIE failure-to-update-on-href-change bug</li>
		<li>Nick Craver - <a href="http://stackoverflow.com/questions/2351278/css-javascript-get-user-visible-text-of-an-element">pointing</a> to the jQuery :visible psuedoselector</li>
		<li>Alex Fink - better processing algorithms and response UI</li>
		<li>Jeremiah Grossman - writing the original CSS History Hack!</li>
		<li>Dan Kaminsky - suggestion to use IFRAMEs for multithreading</li>
		<li>Leif Ryge - suggestions for better input and response UI</li>
		<li>Mike Shaver - the 'grab rendered text' <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=147777#c49">idea</a></li>
	</ul>
</div>
