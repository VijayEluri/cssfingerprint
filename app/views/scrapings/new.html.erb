<div id="participate">
	<h3>Participate</h3>
	
	<noscript>
		<div style="color: red;">
			<p>You currently have JavaScript turned off. Congratulations, I can't scrape you with this... though you're still vulnerable to the <a href="http://ha.ckers.org/weird/CSS-history.cgi">pure-CSS version</a>.</p>
			<p>However, in order for me to collect useful data, I'd appreciate if you turn JS on and click the button. Thanks.</p>
		</div>
	</noscript>
	
	<div style="margin:1em;">
		
		<div id="results"></div>
		<div id="status"></div>
		<% effective_threads.times do |i| %>
			<div id="status_<%= i %>"><% 'Loading javascript...' if i == 0 %></div>
		<% end %>
		<div style="clear:both;"></div>
		<% form_remote_tag(:url => scrapings_url, :method => :post, :html => {:id => 'cookie_form'},
					:loading => update_page {|page| page['status_0'].replace_html "Checking code..."; page['cookie_form'].hide }) do %>
			<p>Enter something unique to you (NOT a password). <%= text_field_tag :cookie, cookies[:remember_token] %> <small> E.g. <%= random_string %></small>
			<br/><span style="color:red;">Please use <b>the same code</b> every time you visit (including from other browsers/computers).</span>
			</p>
			<p>Have you visited before? <%= check_box_tag :repeat_user, '1', !cookies[:remember_token].blank? %></p>
			<p><%= submit_tag "Fingerprint me", :disabled => true %>
				<br/>Warning: DO NOT use this from a public computer. This may cause your computer to run slowly for about a minute; it's normal, just be patient.</p>
		<% end %>
		
		<div id="scrapers" style="width: 1px; height: 1px;"></div>
		
		<%= periodically_call_remote :frequency => 2, :condition => "completed == false", :url => results_scrapings_url(), :method => :get %>
	</div>
	
	
	<p>When you hit the submit button, you'll see "Testing sites 1 through 501...", increasing rapidly 500 at a time, ending with a "Done!" message and a display of your stats. It will take 60 seconds, and scrape about 3k-20k URLs.</p>
	<p>If you get &lt;1000 URLs scraped or 0 hits, or it otherwise behaves oddly, please reload and resubmit. If that doesn't fix it, please IM me ASAP (AIM saizai) so I can debug it. Thanks!</p>
	<p><small>There are a few <a href="#bugs">known bugs</a>.</small></p>
	
	<script>
		// There appears to be an issue that people may be starting the form before the JS is loaded, which prevents the returned AJAX from being executed.
		// So we just disable it until loaded. Kludge but works.
		Event.observe(window, 'load', function(){
			$('cookie_form').enable();
			$('status_0').innerHTML = 'Ready to scrape!'
			completed = true; // will be falsified by the spawner
		});
	</script>
</div>

<div id="selftest">
	<h4>Self test</h4>
	<p>Browsers each have idiosyncracies and require different methods to test efficiently. Here are the results of yours.</p>
	<p>A correct test should say true for cssfingerprint.com, false for the garbage, and true for google if you actually use this browser at all.</p>
	
	<table>
		<script>
			document.write("<tr><th>Method</th>");
			var selftest_urls = ['cssfingerprint.com','google.com', 'adfkljalksdflaesw.com'];
			for(var i = 0; i < selftest_urls.length; i++) {
				document.write("<th>" + selftest_urls[i] + "</th>");
			}
			document.write("</tr>");
			
			<% methods = ['lean','normal','heavy'] %>
			var results = {};
			<% methods.each do |m| %>
				document.write("<tr><td>" + "<%=m%>" + "</td>");
				results[ "<%=m%>"] = CSSHistory.check_batch_with(selftest_urls, "<%=m%>");
				for(var j = 0; j < selftest_urls.length; j++) {
					document.write("<td>" + results[ "<%=m%>"][selftest_urls[j]] + "</td>");
				}
			<% end %>
			document.write("</tr>");
		</script>
	</table>
	
	<div id="selftest_status"></div>
	<%= button_to_remote "Report results", {:url => browser_tests_url, :method => :post, :with => "'results=' + JSON.stringify(results)", :update => 'selftest_status',
			:loading => "$('selftest_report').disable();"}, {:id => 'selftest_report'}  %>
	
	<p>Reporting your results for this test only tells the server your user-agent and the information in the table above; it doesn't test any other URLs. 
	This will help me to create better scraping methods.</p>
</div>

<div id="about">
	<h3>About CSS Fingerprint</h3>

	<p>CSS Fingerprint is a research project inspired by the EFF's <a href="http://panopticlick.eff.org">Panopticlick</a>.</p>

	<p>Its intent is to see how well the <a href="http://ha.ckers.org/weird/CSS-history-hack.html">CSS history hack</a> can be used with "fuzzy" AI techniques to uniquely fingerprint users <i>despite changes in their browsing history, even on new computers or new browsers</i>.</p>

	<p>A weakness of Panopticlick's method is that it is very browser-specific. That means that while they can fairly well identify your exactly configured browser if you visit again, they cannot easily identify <i>you the human</i> if you visit from multiple computers or browsers, even if your behavior is similar.</p>

	<p>At the moment, the AI component is not yet active. In order to write it, I need data.</p>

	<p>To help out, please visit this site from multiple different browsers / computers that you own, on multiple days, using the same input each time.</p>

	<p>Thanks!</p>

	<p>- <A href="http://saizai.com">Sai Emrys</A> (saizai)</p>

	<p>P.S. Thanks to:
		<ul>
			<li>Daniel Bartlett - making an (almost) IE-compatible history hack</li>
			<li>Michael Chui - pinpointing the damn MSIE failure-to-update-on-href-change bug</li>
			<li>Alex Fink - better processing algorithms and response UI</li>
			<li>Jeremiah Grossman - writing the original CSS History Hack!</li>
			<li>Dan Kaminsky - suggestion to use IFRAMEs for multithreading</li>
			<li>Leif Ryge - suggestions for better input and response UI</li>
		</ul>
	</p>
</div>

<div id="geek-about" style="font-size: 80%;">
	<h3>About CSS Fingerprint (for geeks)</h3>
	
	<p>What I store is the cookie value you submit, your user-agent, and, for each of the top ~2-40k Alexa sites (depending on your CPU and internet speed), whether or not you have visited that site.</p>
	
	<p>I make no attempt to find out who you are personally, and I don't store your IP (except temporarily in log files).</p>
	
	<p>The point of this is simply to tell whether I can automatically identify when you visit again with a different browser. To do that, I need training/test data to feed my AI to tell it authoritatively whether two scrapings are the same user or not.</p>
	 <p>Currently, I'm testing naive Bayes, SVD, and SVM; if you have suggestions for other methods or tweaks to what I'm doing now, please check out the repo and email me.</p>
	
	<p>The data will not be shared with anyone except other EFF-friendly researchers who agree to keep it confidential.</p>
	
	<p>The source code is available at <A href="http://github.com/saizai/cssfingerprint">github</A>. Commits welcome.</p>
	
	<p>How it works:
		<ol>
			<li>Scrape <a href="http://www.alexa.com/topsites">Alexa</a>'s <a href="http://s3.amazonaws.com/alexa-static/top-1m.csv.zip">1M top sites list</a> and Technorati's <a href="http://technorati.com/blogs/top100">top 100 blogs list</a> once per day, insert in db</li>
			<li>When form is submitted, find/create a user for the cookie, execute the result in <%= THREADS %> parallel iframes</li>
			<li>Form result is code to test a given batch of URLs (500 at a time) and fetch the next one</li>
			<li>The test is based on Jeremiah Grossman's CSS history hack with Daniel Bartlett's modification for IE compatibility. It inserts a link into the DOM, and checks whether it's styled like the stylesheet says visited links should be. It checks http/https and bare/www. URLs.</li>
			<li>Client uploads the results to the server, recursion happens.</li>
			<li>Server cuts off client after 60 seconds, processes all the data in the background to speed things up</li>
		</ol>
	</p>
	
	<p><a id="bugs">Known issues</a>:
		<ol>
			<li>Alexa top sites list has some glaringly missing things (e.g. mail.google.com, reader.google.com), and the hit rate is consequently rather low (~1% or less). I probably need to supplement it with some other list(s). Suggestions appreciated.</li>
			<li>Android Safari, NT 5.1 Firefox, and Konqueror have not yet worked. Probably something wrong with the getComputedStyle / currentStyle method in the scraper. Patches welcome.</li>
			<li>Lynx, and other browsers that do not fully support CSS/Javascript, will <i>not</i> work correctly. This is not fixable.</li>
			<li>In some circumstances even known visited sites on known supported browsers (e.g. OSX Firefox) don't appear as hits. This may be because my JS scraper has a bug, or because of some browser behavior.</li>
		</ol>
	</p>
</div>